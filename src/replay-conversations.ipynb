{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "<a href=\"https://colab.research.google.com/github/higherbar-ai/open-chat-studio-sim/blob/main/src/replay-conversations.ipynb\" target=\"_parent\"><img alt=\"Open In Colab\" src=\"https://colab.research.google.com/assets/colab-badge.svg\"/></a>\n",
    "\n",
    "# Replay conversations\n",
    "\n",
    "This notebook replays conversations using an Open Chat Studio experiment.\n",
    "\n",
    "## Running in Google Colab\n",
    "\n",
    "Before running this notebook, you'll need to configure a series of secrets in Google Colab; click the key button in the left sidebar, and be sure to click the toggle to give this notebook access to each of the secrets. These are the secrets used by this notebook:\n",
    "\n",
    "- `OCS_API_KEY`: your Open Chat Studio API key\n",
    "- `ATHINA_API_KEY`: your Athina API key (optional; only if you want to export results to Athina)\n",
    "- `EXPERIMENT_ID`: the ID of the experiment you want to issue queries to\n",
    "- `PARTICIPANT_ID`: the participant ID to use for the queries (defaults to \"open-chat-studio-sim\")\n",
    "\n",
    "## Running in a local environment\n",
    "\n",
    "When you first run the first code cell in this notebook, it will output a template configuration file for you. Edit that file to specify your configuration parameters (see above for their descriptions). \n",
    "\n",
    "## Selecting or uploading your conversations to replay\n",
    "\n",
    "The second code cell will prompt you to select or upload a .csv file with the conversations you want to replay. This file should follow the format of experiment session exports in Open Chat Studio. The columns we rely on here are:\n",
    "\n",
    "- `Message ID`: the unique identifier for the chat message\n",
    "- `Message Type`: the chat message type (`human` or `ai`)\n",
    "- `Message Content`: the chat message\n",
    "- `Session ID`: the unique session ID for the conversation\n",
    "\n",
    "## Where results go\n",
    "\n",
    "The results of the queries will be saved to a file called `replayed_conversations.csv`. If you're running in Google Colab, click the folder button in the sidebar to view and download that file. If you're running locally, it will be output to the `ocs` subdirectory off of your local directory. \n",
    "\n",
    "If an Athina API key is configured, the results will also be exported to an Athina dataset."
   ],
   "id": "c978324bbea2d097"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# install support for Google Colab\n",
    "%pip install colab-or-not\n",
    "\n",
    "# set log level to WARNING\n",
    "import logging\n",
    "logging.basicConfig(level=logging.WARNING)\n",
    "\n",
    "# Initialize our environment\n",
    "from colab_or_not import NotebookBridge\n",
    "env = NotebookBridge(\n",
    "    github_repo=\"higherbar-ai/open-chat-studio-sim\",\n",
    "    requirements_path=\"requirements.txt\",\n",
    "    module_paths=[\"src/ocs_api.py\", \"src/ocs_simulation_support.py\"],\n",
    "    config_path=\"~/.ocs/.env\",\n",
    "    config_template={\n",
    "        \"OCS_API_KEY\": \"\",\n",
    "        \"ATHINA_API_KEY\": \"\",\n",
    "        \"EXPERIMENT_ID\": \"\",\n",
    "        \"PARTICIPANT_ID\": \"open-chat-studio-sim\",\n",
    "    }\n",
    ")\n",
    "env.setup_environment()\n",
    "\n",
    "# Internal configuration\n",
    "api_timeout_seconds = 300      # how long to give API calls before timing out\n",
    "api_num_retries = 3            # how many times to retry API calls before giving up\n",
    "api_retry_delay_seconds = 2    # how long to wait between retries\n",
    "continue_on_error = True       # whether to record errors and continue (if False, errors will halt execution)\n",
    "\n",
    "# Get API keys from environment\n",
    "ocs_api_key = env.get_setting(\"OCS_API_KEY\")\n",
    "athina_api_key = env.get_setting(\"ATHINA_API_KEY\")\n",
    "experiment_id = env.get_setting(\"EXPERIMENT_ID\")\n",
    "participant_id = env.get_setting(\"PARTICIPANT_ID\", \"open-chat-studio-sim\")\n",
    "\n",
    "# Validate required configuration\n",
    "if not all([ocs_api_key, experiment_id]):\n",
    "    raise ValueError(\"Please supply at least OCS_API_KEY and EXPERIMENT_ID in your secrets or configuration file.\")\n",
    "\n",
    "# Output files to ~/ocs directory if local, otherwise /content if Google Colab\n",
    "if env.is_colab:\n",
    "    output_path_prefix = \"/content\"\n",
    "else:\n",
    "    import os\n",
    "    output_path_prefix = os.path.expanduser(\"~/ocs\")\n",
    "    os.makedirs(output_path_prefix, exist_ok=True)\n",
    "\n",
    "# Initialize OCS API support\n",
    "from ocs_api import OCSAPIClient    # type: ignore[import]\n",
    "ocs_api_client = OCSAPIClient(\n",
    "    api_key=ocs_api_key, \n",
    "    timeout_seconds=api_timeout_seconds, \n",
    "    num_retries=api_num_retries, \n",
    "    retry_wait_seconds=api_retry_delay_seconds\n",
    ")\n",
    "\n",
    "# Report results\n",
    "print(f\"Configuration loaded for {'Colab' if env.is_colab else 'local'} environment, OCS API initialized.\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Select or upload your conversations to replay\n",
    "\n",
    "The code cell below will prompt you to select or upload a .csv file. This file should follow the format of experiment session exports in Open Chat Studio. The columns we rely on here are:\n",
    "\n",
    "- `Message ID`: the unique identifier for the chat message\n",
    "- `Message Type`: the chat message type (`human` or `ai`)\n",
    "- `Message Content`: the chat message\n",
    "- `Session ID`: the unique session ID for the conversation"
   ],
   "id": "898881e8f441fd3e"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# prompt for the CSV file with conversations to replay\n",
    "to_replay_files = env.get_input_files(\"CSV file with conversations to replay\")\n",
    "\n",
    "# check for one CSV file\n",
    "if len(to_replay_files) != 1:\n",
    "    raise ValueError(\"Please select exactly one CSV file with conversations to replay.\")\n",
    "elif not to_replay_files[0].endswith(\".csv\"):\n",
    "    raise ValueError(\"Please select a CSV file with conversations to replay.\")\n",
    "\n",
    "to_replay_file = str(to_replay_files[0])"
   ],
   "id": "bd47f1f7895d6039",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Replay conversations\n",
    "\n",
    "The following code block reads each human message from the .csv selected or uploaded above, fetches a new AI response from each (using _the original conversation history_), and saves the results to the `replayed_conversations.csv` file. \n",
    "\n",
    "`replayed_conversations.csv` will have the following columns:\n",
    "\n",
    "- `message_id`: the unique identifier for the original query\n",
    "- `session_id`: the unique identifier for the _original_ experiment session being replayed (links conversations)\n",
    "- `replay_session_id`: the unique identifier for the _new_ experiment session created during replay\n",
    "- `query`: the query sent to the AI assistant\n",
    "- `response`: the response received from the AI assistant\n",
    "- `orig_response`: the original response received from the AI assistant\n",
    "- `context`: the raw conversation history included at the time of replay"
   ],
   "id": "910365de62ca7fa"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import csv\n",
    "import pandas as pd\n",
    "import json\n",
    "import os\n",
    "\n",
    "# load input file using pandas\n",
    "conversations_to_replay = pd.read_csv(to_replay_file)\n",
    "\n",
    "# run through and replay each step of each conversation\n",
    "results = []\n",
    "num_sessions = 0\n",
    "orig_session_id = \"\"\n",
    "orig_messages = []\n",
    "user_message = \"\"\n",
    "user_message_id = \"\"\n",
    "session_id = \"\"\n",
    "for index, row in conversations_to_replay.iterrows():\n",
    "    if orig_session_id != row[\"Session ID\"]:\n",
    "        # initialize for new conversations\n",
    "        orig_session_id = row[\"Session ID\"]\n",
    "        orig_messages = []\n",
    "        user_message = \"\"\n",
    "        user_message_id = \"\"\n",
    "        num_sessions += 1\n",
    "    \n",
    "    if row[\"Message Type\"] == \"human\":\n",
    "        # remember user message, but only process when we get to the original AI response\n",
    "        user_message = row[\"Message Content\"]\n",
    "        user_message_id = row[\"Message ID\"]\n",
    "    elif user_message and row[\"Message Type\"] == \"ai\":\n",
    "        # remember original AI response\n",
    "        orig_response = row[\"Message Content\"]\n",
    "    \n",
    "        # report out\n",
    "        print(f\"Replaying message {user_message_id} for session {orig_session_id}...\")\n",
    "        \n",
    "        # replay conversation step, catching and logging any errors\n",
    "        try:\n",
    "            # create a new session for the step, including the original conversation history\n",
    "            api_response = ocs_api_client.create_experiment_session(experiment_id, participant_id, orig_messages)\n",
    "            session_id = api_response[\"id\"]\n",
    "        \n",
    "            # send the user message to the experiment\n",
    "            api_response = ocs_api_client.send_new_api_message(experiment_id, user_message, session_id)\n",
    "            response = api_response[\"response\"]\n",
    "        except Exception as e:\n",
    "            if continue_on_error:\n",
    "                # log the error and continue to the next message\n",
    "                logging.error(f\"Continuing following error fetching conversation response: {str(e)}\")\n",
    "                response = f\"ERROR: {str(e)}\"\n",
    "            else:\n",
    "                # raise the error to halt execution\n",
    "                raise\n",
    "\n",
    "        # add to results\n",
    "        results.append({\n",
    "            \"message_id\": user_message_id,\n",
    "            \"session_id\": orig_session_id,\n",
    "            \"replay_session_id\": session_id,\n",
    "            \"query\": user_message,\n",
    "            \"response\": response,\n",
    "            \"orig_response\": orig_response,\n",
    "            \"context\": json.dumps(orig_messages)\n",
    "        })\n",
    "        \n",
    "        # add original exchange to message history\n",
    "        orig_messages.append({\n",
    "            \"role\": \"user\",\n",
    "            \"content\": user_message\n",
    "        })\n",
    "        orig_messages.append({\n",
    "            \"role\": \"assistant\",\n",
    "            \"content\": orig_response\n",
    "        })\n",
    "\n",
    "# save results to output .csv file\n",
    "output_file = os.path.join(output_path_prefix, \"replayed_conversations.csv\")\n",
    "output_rows = []\n",
    "fieldnames=[\"message_id\", \"session_id\", \"replay_session_id\", \"query\", \"response\", \"orig_response\", \"context\"]\n",
    "with open(output_file, \"w\", newline=\"\") as csvfile:\n",
    "    writer = csv.DictWriter(csvfile, fieldnames=fieldnames, quoting=csv.QUOTE_NONNUMERIC, escapechar='\\\\')\n",
    "    writer.writeheader()\n",
    "    for result in results:\n",
    "        # output and record for potential next steps\n",
    "        writer.writerow(result)\n",
    "        output_rows.append(result)\n",
    "\n",
    "# report results\n",
    "print()\n",
    "print(f\"Replayed {num_sessions} conversations and saved {len(results)} results to {output_file}.\")"
   ],
   "id": "f4f25eef6e656fad",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Optional: Export results to Athina dataset\n",
    "\n",
    "If an Athina API key is configured, the results can be exported to an Athina dataset. The dataset will be named `replayed-conversations-{experiment_id}-{timestamp}` and will contain the rows from the `replayed_conversations.csv` file."
   ],
   "id": "44962167caf10449"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from ocs_simulation_support import athina_create_dataset    # type: ignore[import]\n",
    "\n",
    "# optionally export the results to an Athina dataset\n",
    "if athina_api_key:\n",
    "    # push new dataset to Athina\n",
    "    dataset_name = f\"replayed-conversations-{experiment_id}-{pd.Timestamp.now().strftime('%Y%m%d%H%M%S')}\"\n",
    "    dataset_description = f\"Replayed conversations for experiment {experiment_id} at {pd.Timestamp.now()}\"\n",
    "    try:\n",
    "        dataset = athina_create_dataset(athina_api_key=athina_api_key, dataset_name=dataset_name, dataset_description=dataset_description, dataset_rows=output_rows)\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to create Athina dataset: {e}\")\n",
    "    else:\n",
    "        print(f\"Results exported to Athina dataset {dataset.id} (name: {dataset_name}).\")"
   ],
   "id": "d3a526e15a3accc2",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
